{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UsingMIDI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv3lHmRz45Qv",
        "colab_type": "text"
      },
      "source": [
        "Mounting Google Drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrGfuGf9Eytb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2d44057f-fded-40fa-eea7-988e5f326cb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6rDxORZRYEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from music21 import converter, instrument, note, chord"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYVdmcHm6gGb",
        "colab_type": "text"
      },
      "source": [
        "# **PARSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcMj_LuZ5DlY",
        "colab_type": "text"
      },
      "source": [
        "Traversing The MIDI files and Parsing It"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh-tZVmIIW5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes = []\n",
        "try:\n",
        "  for file in glob.glob(\"/content/drive/My Drive/Music Creation/Database/*.mid\"):\n",
        "    midi = converter.parse(file)\n",
        "    notes_to_parse = None\n",
        "    try:\n",
        "      s2 = instrument.partitionByInstrument(midi)\n",
        "      notes_to_parse = s2.parts[0].recurse() \n",
        "    except: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note):\n",
        "        notes.append(str(element.pitch))\n",
        "      elif isinstance(element, chord.Chord):\n",
        "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    with open('/content/drive/My Drive/Music Creation/Data/notes', 'wb') as filepath:\n",
        "      pickle.dump(notes, filepath)\n",
        "except exception as e :\n",
        "  print(e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zadyq8b5OHm",
        "colab_type": "text"
      },
      "source": [
        "# **ENCODING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "523IPk1Z5kAN",
        "colab_type": "text"
      },
      "source": [
        "Mapping function to map from string-based categorical data to integer-based numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk4iFpscXyE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_vocab = len(set(notes))\n",
        "sequence_length = 100 # can be changed because this is the number which is going to go as a input in RNN \n",
        "sorted_notes = sorted(set(item for item in notes))\n",
        "map_notes = dict((note, number) for number, note in enumerate(sorted_notes))\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    X.append([map_notes[char] for char in sequence_in])\n",
        "    y.append(map_notes[sequence_out])\n",
        "\n",
        "n_patterns = len(X)\n",
        "X = np.reshape(X, (n_patterns, sequence_length, 1))\n",
        "X = X / float(n_vocab)\n",
        "from keras.utils import np_utils\n",
        "y= np_utils.to_categorical(y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELWPp6_X5zvP",
        "colab_type": "text"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI1-d7i86IQx",
        "colab_type": "text"
      },
      "source": [
        "*  LSTM layers\n",
        "*  Dropout layers\n",
        "*  Dense layers\n",
        "*  Activation layer\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3aooossN6-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization as BatchNorm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhdaUG8brLfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc90oywDtsy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4fc2c87-27d7-4af6-8415-d9f5974befe8"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/Music Creation/Weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(filepath,monitor='loss',verbose=0,save_best_only=True,mode='min')\n",
        "model.fit(X, y, epochs=100, batch_size=128,callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  2/446 [..............................] - ETA: 1:08 - loss: 5.8432WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0861s vs `on_train_batch_end` time: 0.1351s). Check your callbacks.\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 4.7536\n",
            "Epoch 2/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 4.5926\n",
            "Epoch 3/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.6006\n",
            "Epoch 4/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.5307\n",
            "Epoch 5/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.4542\n",
            "Epoch 6/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.3849\n",
            "Epoch 7/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.2909\n",
            "Epoch 8/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 4.1863\n",
            "Epoch 9/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 4.0616\n",
            "Epoch 10/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 3.9135\n",
            "Epoch 11/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 3.7487\n",
            "Epoch 12/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 3.5793\n",
            "Epoch 13/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 3.4101\n",
            "Epoch 14/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 3.2544\n",
            "Epoch 15/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 3.1024\n",
            "Epoch 16/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.9571\n",
            "Epoch 17/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.8153\n",
            "Epoch 18/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.6798\n",
            "Epoch 19/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.5475\n",
            "Epoch 20/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.4246\n",
            "Epoch 21/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 2.3146\n",
            "Epoch 22/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 2.2098\n",
            "Epoch 23/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.1193\n",
            "Epoch 24/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 2.0242\n",
            "Epoch 25/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 1.9471\n",
            "Epoch 26/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 1.8636\n",
            "Epoch 27/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.7917\n",
            "Epoch 28/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 1.7187\n",
            "Epoch 29/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.6359\n",
            "Epoch 30/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 1.5661\n",
            "Epoch 31/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.5150\n",
            "Epoch 32/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.4441\n",
            "Epoch 33/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.3917\n",
            "Epoch 34/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 1.3294\n",
            "Epoch 35/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 1.2793\n",
            "Epoch 36/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.2381\n",
            "Epoch 37/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.1848\n",
            "Epoch 38/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.1350\n",
            "Epoch 39/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 1.1014\n",
            "Epoch 40/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 1.0609\n",
            "Epoch 41/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 1.0271\n",
            "Epoch 42/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.9839\n",
            "Epoch 43/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.9511\n",
            "Epoch 44/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.9296\n",
            "Epoch 45/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.8954\n",
            "Epoch 46/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.8649\n",
            "Epoch 47/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.8416\n",
            "Epoch 48/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.8223\n",
            "Epoch 49/100\n",
            "446/446 [==============================] - 83s 186ms/step - loss: 0.7985\n",
            "Epoch 50/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.7752\n",
            "Epoch 51/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.7536\n",
            "Epoch 52/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.7336\n",
            "Epoch 53/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.7050\n",
            "Epoch 54/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.6997\n",
            "Epoch 55/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.6812\n",
            "Epoch 56/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.6616\n",
            "Epoch 57/100\n",
            "446/446 [==============================] - 83s 185ms/step - loss: 0.6499\n",
            "Epoch 58/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.6334\n",
            "Epoch 59/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.6192\n",
            "Epoch 60/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.6062\n",
            "Epoch 61/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5941\n",
            "Epoch 62/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5847\n",
            "Epoch 63/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5730\n",
            "Epoch 64/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.5658\n",
            "Epoch 65/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.5519\n",
            "Epoch 66/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.5380\n",
            "Epoch 67/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5316\n",
            "Epoch 68/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.5264\n",
            "Epoch 69/100\n",
            "446/446 [==============================] - 82s 185ms/step - loss: 0.5159\n",
            "Epoch 70/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5098\n",
            "Epoch 71/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.5019\n",
            "Epoch 72/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4950\n",
            "Epoch 73/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4871\n",
            "Epoch 74/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4821\n",
            "Epoch 75/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4806\n",
            "Epoch 76/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4662\n",
            "Epoch 77/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4580\n",
            "Epoch 78/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4543\n",
            "Epoch 79/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4496\n",
            "Epoch 80/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4482\n",
            "Epoch 81/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4380\n",
            "Epoch 82/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4306\n",
            "Epoch 83/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.4319\n",
            "Epoch 84/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4344\n",
            "Epoch 85/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.4178\n",
            "Epoch 86/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.4180\n",
            "Epoch 87/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.4187\n",
            "Epoch 88/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4093\n",
            "Epoch 89/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.4068\n",
            "Epoch 90/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.4039\n",
            "Epoch 91/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3963\n",
            "Epoch 92/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3916\n",
            "Epoch 93/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.3920\n",
            "Epoch 94/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.3927\n",
            "Epoch 95/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3875\n",
            "Epoch 96/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3881\n",
            "Epoch 97/100\n",
            "446/446 [==============================] - 82s 183ms/step - loss: 0.3887\n",
            "Epoch 98/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3820\n",
            "Epoch 99/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3820\n",
            "Epoch 100/100\n",
            "446/446 [==============================] - 82s 184ms/step - loss: 0.3792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f47230517f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUpg8OefQ2Wp",
        "colab_type": "text"
      },
      "source": [
        "This is just how to get a output using the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzad9GqE0WQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Music Creation/Data/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "n_vocab = len(set(notes))\n",
        "sorted_notes = sorted(set(item for item in notes))\n",
        "map_notes = dict((note, number) for number, note in enumerate(sorted_notes))\n",
        "\n",
        "sequence_length = 100\n",
        "X = []\n",
        "\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    X.append([map_notes[char] for char in sequence_in])\n",
        "\n",
        "\n",
        "n_patterns = len(X)\n",
        "X_normalized = np.reshape(X, (n_patterns, sequence_length, 1))\n",
        "X_normalized = X_normalized / float(n_vocab)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1AaaUAaMQ-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256,input_shape=(X_normalized.shape[1], X_normalized.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(n_vocab))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model.load_weights('/content/drive/My Drive/Music Creation/Weights/weights.hdf5')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SePtpBHWI4xD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5aca12b-ee82-4ced-e7d5-0d701ab4c52b"
      },
      "source": [
        "from music21 import stream\n",
        "start = np.random.randint(0, len(X)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(sorted_notes))\n",
        "pattern = X[start]\n",
        "prediction_output = []\n",
        "\n",
        "for note_index in range(500):\n",
        "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    prediction_input = prediction_input / float(n_vocab)\n",
        "    prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_note[index]\n",
        "    prediction_output.append(result)\n",
        "\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "\n",
        "offset = 0\n",
        "output_notes = []\n",
        "\n",
        "for pattern in prediction_output:\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_sample.mid')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_sample.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}